{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer to Stage C quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "You are working on a spam classification system using regularized logistic regression. “Spam” is a positive class (y = 1) and “not spam” is the negative class (y = 0). You have trained your classifier and there are n = 2000 examples in the test set. The confusion matrix of predicted class vs. actual class is:\n",
    "\n",
    "\n",
    "What is the F1 score of this classifier?\n",
    "\n",
    "#### Answer: 0.3177"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Which method can we use to best fit a data in Logistic Regression?\n",
    "\n",
    "#### Answer: Maximum Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Why do we use weak learners in boosting?\n",
    "\n",
    "#### Answer: To make the algorithm stronger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "A data scientist is evaluating different binary classification models. A false positive result is 5 times more expensive (from a business perspective) than a false negative result. The models should be evaluated based on the following criteria:\n",
    "\n",
    "1) Must have a recall rate of at least 80%\n",
    "\n",
    "2) Must have a false positive rate of 10% or less\n",
    "\n",
    "3) Must minimize business costs\n",
    "\n",
    "After creating each binary classification model, the data scientist generates the corresponding confusion matrix. Which confusion matrix represents the model that satisfies the requirements?\n",
    "\n",
    "#### Answer: TN = 98%, FP = 2%, FN = 18%, TP = 82%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "You are building a classifier and the accuracy is poor on both the training and test sets. Which would you use to try to improve the performance?\n",
    "\n",
    "#### Answer: Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Which of the following is not an Ensemble model?\n",
    "\n",
    "#### Answer: Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "A classifier predicts if insurance claims are fraudulent or not. The cost of paying a fraudulent claim is higher than the cost of investigating a claim that is suspected to be fraudulent. Which metric should we use to evaluate this classifier?\n",
    "\n",
    "#### Answer: Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "\n",
    "The ROC curve above was generated from a classification algorithm. What can we say about this classifier?\n",
    "\n",
    "#### Answer: The accuracy of the model is perfect\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "A random forest classifier was used to classify handwritten digits 0-9 into the numbers they were intended to represent. The confusion matrix below was generated from the results. Based on the matrix, which number was predicted with the least accuracy?\n",
    "\n",
    "#### Answer: 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "\n",
    "A medical company is building a model to predict the occurrence of thyroid cancer. The training data contains 900 negative instances (people who don't have cancer) and 100 positive instances. The resulting model has 90% accuracy, but extremely poor recall. What steps can be used to improve the model's performance? (SELECT TWO OPTIONS\n",
    "\n",
    "#### Answer: Use Boosting algorithm, Collect more data for the positive case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11\n",
    "\n",
    "You are developing a machine learning classification algorithm that categorizes handwritten digits 0-9 into the numbers they represent. How should you pre-process the label data?\n",
    "\n",
    "#### Answer: One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12\n",
    "\n",
    "What is the entropy of the target variable if its actual values are given as:\n",
    "[1,0,1,1,0,1,0]\n",
    "\n",
    "\n",
    "#### Answer: 4/7 log(3/7) + 3/7 log(4/7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 13\n",
    "\n",
    "Which of this is not a good metric for evaluating classification algorithms for data with imbalanced class problems?\n",
    "\n",
    "\n",
    "#### Answer: Accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 14\n",
    "\n",
    "What is the accuracy on the test set using the random forest classifier? In 4 decimal places.\n",
    "\n",
    "#### Answer: 0.9295\n",
    "\n",
    "\n",
    "## Codes shown Below\n",
    "\n",
    "## Importing all important libriaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('Data_for_UCI_named.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tau1</th>\n",
       "      <th>tau2</th>\n",
       "      <th>tau3</th>\n",
       "      <th>tau4</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>g1</th>\n",
       "      <th>g2</th>\n",
       "      <th>g3</th>\n",
       "      <th>g4</th>\n",
       "      <th>stab</th>\n",
       "      <th>stabf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.959060</td>\n",
       "      <td>3.079885</td>\n",
       "      <td>8.381025</td>\n",
       "      <td>9.780754</td>\n",
       "      <td>3.763085</td>\n",
       "      <td>-0.782604</td>\n",
       "      <td>-1.257395</td>\n",
       "      <td>-1.723086</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.859578</td>\n",
       "      <td>0.887445</td>\n",
       "      <td>0.958034</td>\n",
       "      <td>0.055347</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.304097</td>\n",
       "      <td>4.902524</td>\n",
       "      <td>3.047541</td>\n",
       "      <td>1.369357</td>\n",
       "      <td>5.067812</td>\n",
       "      <td>-1.940058</td>\n",
       "      <td>-1.872742</td>\n",
       "      <td>-1.255012</td>\n",
       "      <td>0.413441</td>\n",
       "      <td>0.862414</td>\n",
       "      <td>0.562139</td>\n",
       "      <td>0.781760</td>\n",
       "      <td>-0.005957</td>\n",
       "      <td>stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.971707</td>\n",
       "      <td>8.848428</td>\n",
       "      <td>3.046479</td>\n",
       "      <td>1.214518</td>\n",
       "      <td>3.405158</td>\n",
       "      <td>-1.207456</td>\n",
       "      <td>-1.277210</td>\n",
       "      <td>-0.920492</td>\n",
       "      <td>0.163041</td>\n",
       "      <td>0.766689</td>\n",
       "      <td>0.839444</td>\n",
       "      <td>0.109853</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.716415</td>\n",
       "      <td>7.669600</td>\n",
       "      <td>4.486641</td>\n",
       "      <td>2.340563</td>\n",
       "      <td>3.963791</td>\n",
       "      <td>-1.027473</td>\n",
       "      <td>-1.938944</td>\n",
       "      <td>-0.997374</td>\n",
       "      <td>0.446209</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.929381</td>\n",
       "      <td>0.362718</td>\n",
       "      <td>0.028871</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.134112</td>\n",
       "      <td>7.608772</td>\n",
       "      <td>4.943759</td>\n",
       "      <td>9.857573</td>\n",
       "      <td>3.525811</td>\n",
       "      <td>-1.125531</td>\n",
       "      <td>-1.845975</td>\n",
       "      <td>-0.554305</td>\n",
       "      <td>0.797110</td>\n",
       "      <td>0.455450</td>\n",
       "      <td>0.656947</td>\n",
       "      <td>0.820923</td>\n",
       "      <td>0.049860</td>\n",
       "      <td>unstable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tau1      tau2      tau3      tau4        p1        p2        p3  \\\n",
       "0  2.959060  3.079885  8.381025  9.780754  3.763085 -0.782604 -1.257395   \n",
       "1  9.304097  4.902524  3.047541  1.369357  5.067812 -1.940058 -1.872742   \n",
       "2  8.971707  8.848428  3.046479  1.214518  3.405158 -1.207456 -1.277210   \n",
       "3  0.716415  7.669600  4.486641  2.340563  3.963791 -1.027473 -1.938944   \n",
       "4  3.134112  7.608772  4.943759  9.857573  3.525811 -1.125531 -1.845975   \n",
       "\n",
       "         p4        g1        g2        g3        g4      stab     stabf  \n",
       "0 -1.723086  0.650456  0.859578  0.887445  0.958034  0.055347  unstable  \n",
       "1 -1.255012  0.413441  0.862414  0.562139  0.781760 -0.005957    stable  \n",
       "2 -0.920492  0.163041  0.766689  0.839444  0.109853  0.003471  unstable  \n",
       "3 -0.997374  0.446209  0.976744  0.929381  0.362718  0.028871  unstable  \n",
       "4 -0.554305  0.797110  0.455450  0.656947  0.820923  0.049860  unstable  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.929\n"
     ]
    }
   ],
   "source": [
    "#Drop the stab column due to the direct relationship between stab and stabf\n",
    "df.drop('stab', axis=1, inplace=True)\n",
    "\n",
    "#split into X$y\n",
    "X = df.drop('stabf', axis=1)\n",
    "y = df['stabf']\n",
    "\n",
    "#split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "#here we transform the train $ test set using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "transform_train = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "tranform_test = pd.DataFrame(scaler.transform(X_test))\n",
    "\n",
    "# Here we instantiate a Random forest classifier\n",
    "rfc = RandomForestClassifier(random_state=1)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 15\n",
    "\n",
    "What is the accuracy on the test set using the xgboost classifier? In 4 decimal places.\n",
    "\n",
    "#### Answer: 0.9195\n",
    "\n",
    "## Code Below\n",
    "\n",
    "## NOTE: \n",
    "The reason for getting a different accuracy score(0.9455) on my jupyter notebook was because i just recently installed xgboost using pip,\n",
    "however for this particualr score of (0.9195), i ran the code with Colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9455\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 16\n",
    "\n",
    "What is the accuracy on the test set using the LGBM classifier? In 4 decimal places.\n",
    "\n",
    "#### Answer: 0.9375\n",
    "\n",
    "## Code Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375\n"
     ]
    }
   ],
   "source": [
    "lcf = LGBMClassifier(random_state=1)\n",
    "lcf.fit(X_train, y_train)\n",
    "y_pred = lcf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 17\n",
    "\n",
    "To improve the Extra Trees Classifier, you will use the following parameters (number of estimators, minimum number of samples, minimum number of samples for leaf node and the number of features to consider when looking for the best split) for the hyperparameter grid needed to run a Randomized Cross Validation Search (RandomizedSearchCV). \n",
    "\n",
    "n_estimators = [50, 100, 300, 500, 1000]\n",
    "\n",
    "min_samples_split = [2, 3, 5, 7, 9]\n",
    "\n",
    "min_samples_leaf = [1, 2, 4, 6, 8]\n",
    "\n",
    "max_features = ['auto', 'sqrt', 'log2', None] \n",
    "\n",
    "hyperparameter_grid = {'n_estimators': n_estimators,\n",
    "\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "\n",
    "                       'min_samples_split': min_samples_split,\n",
    "\n",
    "                       'max_features': max_features}\n",
    "\n",
    "Using the ExtraTreesClassifier as your estimator with cv=5, n_iter=10, scoring = 'accuracy', n_jobs = -1, verbose = 1 and random_state = 1. What are the best hyperparameters from the randomized search CV?\n",
    "\n",
    "#### Answer: N_estimators = 1000 , min_samples_split = 2 , min_samples_leaf = 8, max_features = None\n",
    "\n",
    "\n",
    "## Code Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   48.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   56.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 8,\n",
       " 'max_features': None}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "np.random.seed(1)\n",
    "\n",
    "hyperparameter_grid = {'n_estimators': [50, 100, 300, 500, 1000],\n",
    "        'min_samples_split':[2, 3, 5, 7, 9],\n",
    "        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
    "        'max_features':  ['auto', 'sqrt', 'log2', None]}\n",
    "\n",
    "# Split into X&y\n",
    "X = df.drop('stabf', axis=1)\n",
    "y = df['stabf']\n",
    "\n",
    "# Split into train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate Extra tree classifier\n",
    "ext = ExtraTreesClassifier()\n",
    "\n",
    "# Setup RandomSearchCv\n",
    "rs_clf = RandomizedSearchCV(estimator=ext,\n",
    "                            param_distributions=hyperparameter_grid,\n",
    "                            n_iter=10,\n",
    "                            scoring='accuracy',\n",
    "                            n_jobs=-1,\n",
    "                            random_state=1,\n",
    "                            cv=5,\n",
    "                            verbose=1)\n",
    "\n",
    "# Fit the RandomizedSearchCV version of clf\n",
    "rs_clf.fit(X_train, y_train);\n",
    "\n",
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 18\n",
    "\n",
    "Train a new ExtraTreesClassifier Model with the new Hyperparameters from the RandomizedSearchCV (with random_state = 1). Is the accuracy of the new optimal model higher or lower than the initial ExtraTreesClassifier model with no hyperparameter tuning?\n",
    "\n",
    "#### Answer: Lower\n",
    "\n",
    "## Code Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.928\n"
     ]
    }
   ],
   "source": [
    "# Drop the stab column due to the direct relationship between stab and stabf\n",
    "df.drop('stab', axis=1, inplace=True)\n",
    "\n",
    "# Split into X$y\n",
    "X = df.drop('stabf', axis=1)\n",
    "y = df['stabf']\n",
    "\n",
    "# Split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Here we transform the train $ test set using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "transform_train = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "tranform_test = pd.DataFrame(scaler.transform(X_test))\n",
    "\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "xtree = ExtraTreesClassifier(random_state=1)\n",
    "xtree.fit(X_train, y_train)\n",
    "y_prediction = xtree.predict(X_test)\n",
    "print(accuracy_score(y_test, y_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Accuracy score of the new Extra Tree Clssifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927\n"
     ]
    }
   ],
   "source": [
    "#Drop the stab column due to the direct relationship between stab and stabf\n",
    "df.drop('stab', axis=1, inplace=True)\n",
    "\n",
    "# Split into X$y\n",
    "X = df.drop('stabf', axis=1)\n",
    "y = df['stabf']\n",
    "\n",
    "# Split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Here we transform the train $ test set using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "transform_train = pd.DataFrame(scaler.fit_transform(X_train))\n",
    "tranform_test = pd.DataFrame(scaler.transform(X_test))\n",
    "\n",
    "# New hyperparameters from the RandomizedSearchCv\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "ext_tree = ExtraTreesClassifier(n_estimators=1000,\n",
    "                                random_state=1,\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=8,\n",
    "                                max_features=None)\n",
    "ext_tree.fit(X_train, y_train)\n",
    "ext_preds = ext_tree.predict(X_test)\n",
    "print(accuracy_score(y_test, ext_preds))\n",
    "#0.927"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 19\n",
    "\n",
    "What other hyperparameter optimization methods can you try apart from Random Search?\n",
    "\n",
    "#### Answer: All of the above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 20\n",
    "\n",
    "Find the feature importance using the optimal ExtraTreesClassifier model. Which features are the most and least important respectively?\n",
    "\n",
    "\n",
    "#### Answer: tau2, p1\n",
    "\n",
    "## Code Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tau1    0.137240\n",
       "tau2    0.140508\n",
       "tau3    0.134680\n",
       "tau4    0.135417\n",
       "p1      0.003684\n",
       "p2      0.005337\n",
       "p3      0.005429\n",
       "p4      0.004963\n",
       "g1      0.102562\n",
       "g2      0.107578\n",
       "g3      0.113063\n",
       "g4      0.109541\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = pd.Series(ext_tree.feature_importances_, index=X.columns)\n",
    "#we use the barh to present the features in a horizontal bar plot\n",
    "feature_importance.nlargest(12).plot(kind='barh') \n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THANK YOU!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
